# **QwenRAG - Retrieval-Augmented Generation with FAISS & Ollama**

QwenRAG is a **free and open-source Retrieval-Augmented Generation (RAG) application** that leverages **FAISS** for vector storage and **Ollama** for LLM inference using the `qwen2.5:0.5b` model. This project allows efficient document retrieval and AI-generated responses.

---

## **ğŸš€ Features**
- Uses **FAISS** for fast similarity search
- Runs **Qwen2.5-0.5B** model locally via **Ollama**
- Accepts user queries and retrieves relevant documents
- Generates AI-based responses using the retrieved context
- No paid API required â€” **fully local & open-source!**

---

## **ğŸ“‚ Project Structure**
```
QwenRAG/
â”‚â”€â”€ data/                # Folder containing text documents
â”‚   â”œâ”€â”€ sample.txt       # Example document
â”‚â”€â”€ faiss_index.bin      # FAISS vector index file
â”‚â”€â”€ doc_ids.npy          # Document ID mapping for FAISS
â”‚â”€â”€ retrieve.py          # Document retrieval logic
â”‚â”€â”€ generate.py          # AI response generation using Ollama
â”‚â”€â”€ README.md            # Project documentation
```

---

## **ğŸ› ï¸ Installation & Setup**

### **1ï¸âƒ£ Install Dependencies**
Make sure you have **Python 3.10+**, `pip`, and `git` installed. Then, install the required Python packages:
```sh
pip install faiss-cpu numpy sentence-transformers ollama
```

### **2ï¸âƒ£ Install & Run Ollama**
1. **Install Ollama** (if not installed):
   ```sh
   iwr https://ollama.com/install.ps1 -useb | iex   # Windows
   curl -fsSL https://ollama.com/install.sh | sh   # Linux/macOS
   ```
2. **Pull the Qwen2.5-0.5B model:**
   ```sh
   ollama pull qwen2.5:0.5b
   ```
3. **Verify Ollama is working:**
   ```sh
   ollama run qwen2.5:0.5b
   ```

---

## **ğŸ“Œ How to Use**

### **1ï¸âƒ£ Index Documents**
Ensure that your documents are inside the `data/` folder. If needed, modify `retrieve.py` to load your own text files.

### **2ï¸âƒ£ Retrieve Relevant Documents**
Run the retrieval script:
```sh
python retrieve.py
```
This script loads the FAISS index and retrieves documents based on user queries.

### **3ï¸âƒ£ Generate AI Responses**
Once documents are retrieved, use the `generate.py` script to generate responses:
```sh
python generate.py
```

---

## **ğŸ’¡ Example Usage**
### **Retrieval (`retrieve.py`)**
```sh
Query: "What is machine learning?"
Retrieved Documents: ["Machine learning is a field of AI that allows computers to learn patterns from data..."]
```

### **Generation (`generate.py`)**
```sh
Generated Response: "Machine learning is a branch of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed..."
```

---

## **ğŸ¤– Future Improvements**
âœ… Add a web UI using **Streamlit**
âœ… Support multi-file document ingestion
âœ… Implement a chatbot interface

---

## **ğŸ“ License**
This project is licensed under the **MIT License**.

---

## **ğŸ‘¨â€ğŸ’» Contributing**
Pull requests are welcome! Feel free to submit issues or suggest improvements.

**Happy Coding! ğŸš€**

